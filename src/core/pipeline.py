import json
import os
from datetime import datetime
import sys

# Ajouter les chemins pour les imports
current_dir = os.path.dirname(__file__)
utils_dir = os.path.join(os.path.dirname(current_dir), "utils")
sys.path.insert(0, utils_dir)
sys.path.insert(0, current_dir)

from agent_task import (
    filtrer_email,
    extract_tasks_from_email,
    suggere_taches_implicites,
    resume_email,
    identifier_departement,
    deduire_priorite,
    # ğŸš€ NOUVELLES FONCTIONS OPTIMISÃ‰ES
    extract_tasks_optimized,
    suggere_taches_implicites_optimized,
    resume_email_optimized
)
# Import du nouveau systÃ¨me de cache pour dÃ©tecter les emails redondants
from cache_emails import (
    calculer_hash_email,
    est_email_deja_traite,
    marquer_email_traite,
    obtenir_info_cache,
    obtenir_statistiques_cache
)
# Import du nouveau systÃ¨me de batch processing pour performance
from batch_processor import BatchProcessor
# ğŸš¦ NOUVEAU: Import du systÃ¨me Rate Limiting + Queue  
from rate_limiter import RateLimiter
from email_queue import EmailQueue, detecter_priorite_email_pour_queue

# ğŸ”„ NOUVEAU: Import du gestionnaire unifiÃ© pour PHASE 2
try:
    from unified_task_manager import get_unified_task_manager
    UNIFIED_SYSTEM_AVAILABLE = True
except ImportError:
    UNIFIED_SYSTEM_AVAILABLE = False
    print("âš ï¸ SystÃ¨me unifiÃ© non disponible, utilisation du systÃ¨me legacy")

# Configuration des fichiers de donnÃ©es
# Chemin absolu basÃ© sur le rÃ©pertoire racine du projet
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_FILE = os.path.join(BASE_DIR, "data", "tasks.json")
EMAIL_FILE = os.path.join(BASE_DIR, "data", "emails.json")
LOG_FILE = os.path.join(BASE_DIR, "data", "logs.json")
UNIFIED_TASKS_FILE = os.path.join(BASE_DIR, "data", "unified_tasks.json")

def traiter_emails(
    use_rate_limiting=False,
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    ğŸš€ FONCTION PRINCIPALE UNIFIÃ‰E: Traitement des emails avec toutes amÃ©liorations.
    
    Args:
        use_rate_limiting (bool): Active le rate limiting + queue pour protection surcharge
        use_batch_processing (bool): Active le traitement par batch intelligent  
        use_cache (bool): Active le cache anti-doublon pour Ã©conomies IA
        use_optimized_prompts (bool): Active les prompts IA optimisÃ©s
                                 
    IntÃ¨gre TOUTES les optimisations pour la production :
    âœ… 1. Cache anti-doublon (Ã©conomies IA) 
    âœ… 2. Batch processing intelligent
    âœ… 3. Rate limiting + Queue (protection surcharge)
    âœ… 4. Optimisation prompts IA (qualitÃ© + Ã©conomies)
    """
    print("ğŸš€ DÃ©marrage traitement intelligent des emails...")
    
    # Afficher les optimisations actives
    optimisations = []
    if use_cache:
        optimisations.append("Cache anti-doublon")
    if use_batch_processing:
        optimisations.append("Batch processing")
    if use_rate_limiting:
        optimisations.append("Rate limiting + Queue")
    if use_optimized_prompts:
        optimisations.append("Prompts optimisÃ©s")
    
    print(f"ï¿½ Optimisations actives: {', '.join(optimisations)}")
    
    # ğŸš¦ Router vers la bonne mÃ©thode selon le mode
    if use_rate_limiting:
        print("ğŸš¦ Mode Rate Limiting + Queue activÃ©")
        return traiter_emails_avec_rate_limiting(
            use_batch_processing=use_batch_processing,
            use_cache=use_cache,
            use_optimized_prompts=use_optimized_prompts
        )
    else:
        print("âš¡ Mode classique (performances maximales)")
        return traiter_emails_mode_classique(
            use_batch_processing=use_batch_processing,
            use_cache=use_cache,
            use_optimized_prompts=use_optimized_prompts
        )


# ğŸ¯ FONCTIONS HELPER POUR OPTIMISATION IA
# ==========================================

def extraire_taches_avec_options(texte_email: str, type_detecte: str, use_optimized_prompts: bool) -> str:
    """
    Helper function qui choisit entre versions optimisÃ©es ou standard.
    
    Args:
        texte_email: Contenu de l'email
        type_detecte: "explicite" ou "implicite" 
        use_optimized_prompts: Utiliser prompts optimisÃ©s
        
    Returns:
        str: JSON des tÃ¢ches extraites
    """
    if type_detecte == "explicite":
        if use_optimized_prompts:
            return extract_tasks_optimized(texte_email, use_optimized_prompts=True)
        else:
            return extract_tasks_from_email(texte_email)
    else:  # implicite
        if use_optimized_prompts:
            return suggere_taches_implicites_optimized(texte_email, use_optimized_prompts=True)
        else:
            return suggere_taches_implicites(texte_email)


def resumer_email_avec_options(texte_email: str, use_optimized_prompts: bool) -> str:
    """
    Helper function pour rÃ©sumer un email avec ou sans optimisation.
    
    Args:
        texte_email: Contenu de l'email
        use_optimized_prompts: Utiliser prompts optimisÃ©s
        
    Returns:
        str: RÃ©sumÃ© de l'email
    """
    if use_optimized_prompts:
        return resume_email_optimized(texte_email, use_optimized_prompts=True)
    else:
        return resume_email(texte_email)


def traiter_emails_mode_classique(
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    ğŸ”§ MODE CLASSIQUE: Traitement sans rate limiting (code existant intact).
    Exactement le mÃªme comportement qu'avant.
    """
    print("âš¡ Traitement mode classique...")
    
    # Charger emails.json
    with open(EMAIL_FILE, "r", encoding="utf-8") as f:
        emails = json.load(f)

    # Charger tasks.json
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        tasks_data = json.load(f)

    # Initialiser le processeur de batch
    batch_processor = BatchProcessor(batch_size_normal=5, batch_size_urgent=2)
    
    # Compteurs pour statistiques
    taches_totales = 0
    emails_doublons_detectes = 0
    emails_traites_batch = 0
    batches_traites = 0

    # 1. ğŸ” PHASE CACHE: Traiter d'abord les doublons (comme avant)
    emails_apres_cache = []
    
    for email in emails:
        # VÃ©rifier statut traitement
        if email["statut_traitement"] == "traitÃ©":
            emails_apres_cache.append(email)
            continue

        # VÃ©rification cache (logique existante preservÃ©e)
        email_hash = calculer_hash_email(email["texte"], email["objet"])
        
        if est_email_deja_traite(email_hash):
            # Email en cache - traitement identique Ã  l'original
            info_cache = obtenir_info_cache(email_hash)
            
            email["statut_traitement"] = "traitÃ© (doublon)"
            email["hash_email"] = email_hash
            email["type_email"] = info_cache.get("type_email", "inconnu") if info_cache else "inconnu"
            email["nb_taches_extraites"] = 0

            log_entree = {
                "horodatage": datetime.now().isoformat(timespec='seconds'),
                "email_objet": email["objet"],
                "statut": "doublon dÃ©tectÃ©",
                "type_detecte": "cache_hit",
                "hash_email": email_hash,
                "email_original_traite_le": info_cache.get("processed_at") if info_cache else "inconnu",
                "economies_ia": "Appel OpenRouter Ã©vitÃ©"
            }
            enregistrer_log(log_entree)
            
            emails_doublons_detectes += 1
            print(f"ğŸŸ¡ Doublon dÃ©tectÃ© (hash: {email_hash}) â€” Email ignorÃ© : {email['objet']}")
        
        emails_apres_cache.append(email)

    # 2. ğŸ¯ PHASE BATCH: CrÃ©er batches intelligents pour emails restants
    batches = batch_processor.creer_batches_intelligents(emails_apres_cache)
    
    if not batches:
        print("â„¹ï¸ Aucun email nouveau Ã  traiter par batch")
    else:
        stats_batch = batch_processor.obtenir_statistiques_batch(batches)
        print(f"ğŸ“¦ {stats_batch['total_batches']} batches crÃ©Ã©s pour {stats_batch['total_emails']} emails")
        print(f"   âš¡ Urgents: {stats_batch['batches_urgents']} batches")
        print(f"   ğŸ“‹ Normaux: {stats_batch['batches_normaux']} batches")

    # 3. ğŸ¤– PHASE TRAITEMENT: Traiter chaque batch
    for batch in batches:
        print(f"\nğŸ”„ Traitement batch {batch['id']} ({batch['type']}) - {batch['taille']} emails")
        
        # Traiter emails du batch individuellement (garde logique existante)
        for email in batch["emails"]:
            try:
                # ğŸš€ Traitement avec options d'optimisation
                resultat = traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts)
                
                if resultat["statut"] == "succÃ¨s":
                    taches_totales += resultat["nb_taches"]
                    emails_traites_batch += 1
                    
                    # Marquer dans cache (logique existante)
                    marquer_email_traite(resultat["hash_email"], {
                        "objet": email["objet"],
                        "expediteur": email["expediteur"],
                        "destinataire": email["destinataire"],
                        "nb_taches": resultat["nb_taches"],
                        "type_email": resultat["type_detecte"]
                    })
                    
                    print(f"   âœ… Email traitÃ©: {resultat['nb_taches']} tÃ¢ches extraites")
                else:
                    print(f"   âŒ Erreur email: {resultat.get('erreur', 'Inconnue')}")
                    
            except Exception as e:
                print(f"   âŒ Erreur traitement email: {str(e)}")
                # Log d'erreur
                log_entree = {
                    "horodatage": datetime.now().isoformat(timespec='seconds'),
                    "email_objet": email.get("objet", "unknown"),
                    "statut": "Ã©chec batch",
                    "erreur": str(e),
                    "batch_id": batch["id"]
                }
                enregistrer_log(log_entree)
        
        batches_traites += 1
        print(f"âœ… Batch {batch['id']} terminÃ©")

    # 4. ğŸ’¾ SAUVEGARDE: Compatible ancien + nouveau systÃ¨me
    # LEGACY: Sauvegarder dans l'ancien format (prÃ©servÃ©)
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(tasks_data, f, indent=4, ensure_ascii=False)

    # ğŸ”„ NOUVEAU: Sauvegarder aussi dans le systÃ¨me unifiÃ© si disponible
    if UNIFIED_SYSTEM_AVAILABLE and os.path.exists(UNIFIED_TASKS_FILE):
        try:
            unified_manager = get_unified_task_manager()
            # Ajouter nouvelles tÃ¢ches au systÃ¨me unifiÃ©
            for task in tasks_data:
                # VÃ©rifier si la tÃ¢che n'existe pas dÃ©jÃ 
                existing_unified_tasks = unified_manager.load_all_tasks()
                task_exists = any(
                    ut.get("source_metadata", {}).get("email_id") == task.get("id")
                    for ut in existing_unified_tasks
                )
                
                if not task_exists:
                    # Convertir vers format unifiÃ©
                    unified_task_data = {
                        "description": task.get("description", ""),
                        "responsable": task.get("responsable", ""),
                        "deadline": task.get("deadline"),
                        "priorite": task.get("priorite", "medium"),
                        "statut": task.get("statut", "pending"),
                        "confiance_ia": task.get("confiance_ia", 0.8),
                        "source": "email",
                        "type": task.get("type", "explicite"),
                        "source_metadata": {
                            "email_id": task.get("id"),
                            "original_email": task.get("origine_email", {})
                        }
                    }
                    unified_manager.add_task(unified_task_data)
            print("âœ… TÃ¢ches sauvegardÃ©es dans le systÃ¨me unifiÃ©")
        except Exception as e:
            print(f"âš ï¸ Erreur sauvegarde systÃ¨me unifiÃ©: {e}")
    
    with open(EMAIL_FILE, "w", encoding="utf-8") as f:
        json.dump(emails_apres_cache, f, indent=4, ensure_ascii=False)

    # 5. ğŸ“Š STATISTIQUES: Enrichies avec info batch et cache
    stats_cache = obtenir_statistiques_cache()
    
    resume = {
        "emails_traitees": len(emails),  # CompatibilitÃ© avec l'ancien format
        "emails_traites_batch": emails_traites_batch,
        "taches_ajoutees": taches_totales,
        "doublons_detectes": emails_doublons_detectes,
        "batches_traites": batches_traites,
        "economies_ia": f"{emails_doublons_detectes} appels OpenRouter Ã©vitÃ©s par cache",
        "efficacite_batch": f"{batches_traites} batches vs {emails_traites_batch} emails individuels",
        "cache_stats": {
            "total_emails_en_cache": stats_cache.get("total_emails_caches", 0),
            "cache_fonctionnel": stats_cache.get("cache_existe", False)
        }
    }
    
    # Affichage rÃ©sumÃ© enrichi
    print(f"\nğŸ“Š RÃ©sumÃ© du traitement intelligent:")
    print(f"   ğŸ“§ Emails total: {len(emails)}")
    print(f"   ğŸš€ Emails traitÃ©s: {emails_traites_batch}")
    print(f"   âœ… Nouvelles tÃ¢ches: {taches_totales}")
    print(f"   ğŸŸ¡ Doublons Ã©vitÃ©s: {emails_doublons_detectes}")
    print(f"   ğŸ“¦ Batches utilisÃ©s: {batches_traites}")
    print(f"   ğŸ’° Ã‰conomies cache: {emails_doublons_detectes} appels Ã©vitÃ©s")
    print(f"   ğŸ—„ï¸ Cache total: {stats_cache.get('total_emails_caches', 0)} emails")
    
    return resume

def traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts=True):
    """
    Traite un email individuel avec la logique complÃ¨te du pipeline original.
    UtilisÃ© par le systÃ¨me de batch pour garder la compatibilitÃ©.
    
    Args:
        email: Email Ã  traiter
        tasks_data: DonnÃ©es des tÃ¢ches existantes
        use_optimized_prompts: Utiliser les prompts IA optimisÃ©s
    """
    
    texte = email["texte"]
    email_hash = calculer_hash_email(email["texte"], email["objet"])

    # Filtrer email (logique originale)
    type_detecte = filtrer_email(texte)

    # ğŸš€ NOUVEAU: Extraction avec prompts optimisÃ©s selon paramÃ¨tre
    result_text = extraire_taches_avec_options(texte, type_detecte, use_optimized_prompts)

    try:
        taches = json.loads(result_text)
        if not isinstance(taches, list):
            raise ValueError("RÃ©sultat IA n'est pas une liste")
    except Exception as e:
        # Log d'erreur (logique originale)
        log_entree = {
            "horodatage": datetime.now().isoformat(timespec='seconds'),
            "email_objet": email["objet"],
            "statut": "Ã©chec",
            "type_detecte": type_detecte,
            "erreur": str(e),
            "resultat_ia": result_text
        }
        enregistrer_log(log_entree)
        
        email["statut_traitement"] = "traitÃ©"
        email["type_email"] = type_detecte
        email["nb_taches_extraites"] = 0
        email["hash_email"] = email_hash
        
        return {"statut": "Ã©chec", "erreur": str(e), "nb_taches": 0}

    # ğŸš€ NOUVEAU: RÃ©sumÃ© avec prompts optimisÃ©s selon paramÃ¨tre
    resume = resumer_email_avec_options(texte, use_optimized_prompts)
    if email.get("departement"):
        departement_info = {"nom": email["departement"], "origine": "Utilisateur"}
    else:
        nom_dept = identifier_departement(texte)
        departement_info = {"nom": nom_dept, "origine": "AI"}

    origine_email = {
        "expediteur": email["expediteur"],
        "destinataire": email["destinataire"],
        "objet": email["objet"],
        "date_reception": email["date_reception"],
        "resume_contenu": resume,
        "departement": departement_info
    }

    # Enrichissement tÃ¢ches (logique originale)
    nouvelles_taches = []
    for tache in taches:
        tache["id"] = f"{email['id']}_{len(nouvelles_taches)+1}"
        if not tache.get("responsable"):
            tache["responsable"] = "inconnu"
        if not tache.get("priorite"):
            tache["priorite"] = deduire_priorite(tache["description"])
        if type_detecte == "explicite":
            tache["confiance_ia"] = 1.0
        elif not tache.get("confiance_ia"):
            tache["confiance_ia"] = 0.7

        tache["source"] = "email"
        tache["type"] = type_detecte
        tache["extrait_le"] = datetime.now().isoformat(timespec='seconds')
        tache["statut"] = "Ã  faire"
        tache["origine_email"] = origine_email

        tasks_data.append(tache)
        nouvelles_taches.append(tache)

    # Mise Ã  jour email (logique originale)
    email["statut_traitement"] = "traitÃ©"
    email["type_email"] = type_detecte
    email["nb_taches_extraites"] = len(nouvelles_taches)
    email["hash_email"] = email_hash

    # Log succÃ¨s (logique originale avec mention batch)
    log_entree = {
        "horodatage": datetime.now().isoformat(timespec='seconds'),
        "email_objet": email["objet"],
        "statut": "succÃ¨s",
        "type_detecte": type_detecte,
        "nb_taches": len(nouvelles_taches),
        "hash_email": email_hash,
        "cache_status": "nouveau_email_ajoute_au_cache",
        "traitement_mode": "batch"
    }
    enregistrer_log(log_entree)

    return {
        "statut": "succÃ¨s",
        "type_detecte": type_detecte,
        "nb_taches": len(nouvelles_taches),
        "hash_email": email_hash
    }

# Fonction utilitaire pour Ã©crire dans logs.json
def enregistrer_log(entree):
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", encoding="utf-8") as f:
            json.dump([], f, indent=4, ensure_ascii=False)

    with open(LOG_FILE, "r", encoding="utf-8") as f:
        logs = json.load(f)

    logs.append(entree)

    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(logs, f, indent=4, ensure_ascii=False)


def traiter_emails_avec_rate_limiting(
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    ğŸš¦ NOUVEAU MODE: Traitement avec Rate Limiting + Queue.
    Respecte les limites d'appels IA et utilise une file d'attente intelligente.
    """
    print("ğŸš¦ DÃ©marrage traitement avec rate limiting...")
    
    # Initialiser le rate limiter et la queue
    rate_limiter = RateLimiter(
        calls_per_minute=30,    # Limite conservatrice pour production
        calls_per_hour=800,
        calls_per_day=5000
    )
    email_queue = EmailQueue(max_queue_size=1000)
    
    # Charger emails.json
    with open(EMAIL_FILE, "r", encoding="utf-8") as f:
        emails = json.load(f)

    # Charger tasks.json
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        tasks_data = json.load(f)
    
    # Statistiques
    taches_totales = 0
    emails_doublons_detectes = 0
    emails_traites = 0
    appels_ia_effectues = 0
    temps_attente_total = 0.0
    
    print(f"ğŸ“§ {len(emails)} emails Ã  analyser...")
    
    # 1. ğŸ” PHASE CACHE: Traiter les doublons AVANT la queue
    emails_apres_cache = []
    
    for email in emails:
        if email["statut_traitement"] == "traitÃ©":
            emails_apres_cache.append(email)
            continue

        # VÃ©rification cache (mÃªme logique qu'avant)
        email_hash = calculer_hash_email(email["texte"], email["objet"])
        
        if est_email_deja_traite(email_hash):
            # Email en cache - pas besoin d'IA
            info_cache = obtenir_info_cache(email_hash)
            
            email["statut_traitement"] = "traitÃ© (doublon)"
            email["hash_email"] = email_hash
            email["type_email"] = info_cache.get("type_email", "inconnu") if info_cache else "inconnu"
            email["nb_taches_extraites"] = 0

            log_entree = {
                "horodatage": datetime.now().isoformat(timespec='seconds'),
                "email_objet": email["objet"],
                "statut": "doublon dÃ©tectÃ©",
                "type_detecte": "cache_hit",
                "hash_email": email_hash,
                "mode_traitement": "rate_limited",
                "economies_ia": "Appel OpenRouter Ã©vitÃ©"
            }
            enregistrer_log(log_entree)
            
            emails_doublons_detectes += 1
            print(f"ğŸŸ¡ Doublon dÃ©tectÃ© - Ã‰vite appel IA : {email['objet']}")
        
        emails_apres_cache.append(email)
    
    print(f"âœ… Phase cache terminÃ©e: {emails_doublons_detectes} doublons Ã©vitÃ©s")
    
    # 2. ğŸ“‹ PHASE QUEUE: Mettre les emails non-traitÃ©s en file d'attente
    emails_a_traiter = [e for e in emails_apres_cache if e["statut_traitement"] != "traitÃ©"]
    
    for email in emails_a_traiter:
        priority = detecter_priorite_email_pour_queue(email)
        email_queue.add_email(email, priority)
    
    queue_stats_initial = email_queue.get_queue_stats()
    print(f"ğŸ“‹ File d'attente crÃ©Ã©e:")
    print(f"   ğŸš¨ Urgents: {queue_stats_initial['current_queue']['urgent_count']}")
    print(f"   ğŸ“‹ Normaux: {queue_stats_initial['current_queue']['normal_count']}")
    print(f"   ğŸ“¦ Batch: {queue_stats_initial['current_queue']['batch_count']}")
    
    # 3. ğŸš¦ PHASE TRAITEMENT: Traiter la queue avec rate limiting
    print(f"\nğŸš¦ DÃ©but traitement avec rate limiting...")
    
    while True:
        # RÃ©cupÃ©rer le prochain email de la queue
        email = email_queue.get_next_email()
        if not email:
            break
        
        # VÃ©rifier rate limiting
        if not rate_limiter.can_make_call():
            wait_time = rate_limiter.wait_if_needed()
            temps_attente_total += wait_time
        
        # ğŸš€ Traiter l'email avec toutes les optimisations
        try:
            resultat = traiter_email_individuel_avec_cache_et_rate_limiting(
                email, tasks_data, rate_limiter, use_optimized_prompts
            )
            
            if resultat["statut"] == "succÃ¨s":
                taches_totales += resultat["nb_taches"]
                emails_traites += 1
                appels_ia_effectues += 1
                
                # Marquer dans cache
                marquer_email_traite(resultat["hash_email"], {
                    "objet": email["objet"],
                    "expediteur": email["expediteur"],
                    "destinataire": email["destinataire"],
                    "nb_taches": resultat["nb_taches"],
                    "type_email": resultat["type_detecte"]
                })
                
                print(f"   âœ… Email traitÃ©: {resultat['nb_taches']} tÃ¢ches | Queue: {email_queue.get_total_queue_size()} restants")
            else:
                print(f"   âŒ Erreur: {resultat.get('erreur', 'Inconnue')}")
                
        except Exception as e:
            print(f"   âŒ Erreur traitement: {str(e)}")
    
    # 4. ğŸ’¾ SAUVEGARDE: Identique aux autres modes
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(tasks_data, f, indent=4, ensure_ascii=False)

    with open(EMAIL_FILE, "w", encoding="utf-8") as f:
        json.dump(emails_apres_cache, f, indent=4, ensure_ascii=False)
    
    # 5. ğŸ“Š STATISTIQUES: Enrichies avec rate limiting
    stats_cache = obtenir_statistiques_cache()
    rate_limiter_stats = rate_limiter.get_current_stats()
    queue_stats_final = email_queue.get_queue_stats()
    
    resume = {
        "emails_traitees": len(emails),
        "emails_traites_rate_limited": emails_traites,
        "taches_ajoutees": taches_totales,
        "doublons_detectes": emails_doublons_detectes,
        "appels_ia_effectues": appels_ia_effectues,
        "temps_attente_total": round(temps_attente_total, 2),
        "economies_ia": f"{emails_doublons_detectes} appels Ã©vitÃ©s par cache",
        "rate_limiting_stats": {
            "calls_remaining_minute": rate_limiter_stats["remaining"]["minute"],
            "calls_remaining_hour": rate_limiter_stats["remaining"]["hour"],
            "total_calls_today": rate_limiter_stats["total_calls_today"]
        },
        "queue_stats": {
            "emails_processed": queue_stats_final["overall_stats"]["total_processed"],
            "average_wait_time": round(queue_stats_final["overall_stats"]["average_wait_time"], 2),
            "queue_health": queue_stats_final["queue_health"]["status"]
        },
        "cache_stats": {
            "total_emails_en_cache": stats_cache.get("total_emails_caches", 0),
            "cache_fonctionnel": stats_cache.get("cache_existe", False)
        }
    }
    
    # Affichage rÃ©sumÃ© dÃ©taillÃ©
    print(f"\nğŸ“Š RÃ©sumÃ© du traitement avec Rate Limiting:")
    print(f"   ğŸ“§ Emails total: {len(emails)}")
    print(f"   ğŸš€ Emails traitÃ©s: {emails_traites}")
    print(f"   âœ… Nouvelles tÃ¢ches: {taches_totales}")
    print(f"   ğŸŸ¡ Doublons Ã©vitÃ©s: {emails_doublons_detectes}")
    print(f"   ğŸ¤– Appels IA effectuÃ©s: {appels_ia_effectues}")
    print(f"   â±ï¸ Temps attente total: {temps_attente_total:.1f}s")
    print(f"   ğŸš¦ Appels restants/heure: {rate_limiter_stats['remaining']['hour']}")
    print(f"   ğŸ“‹ SantÃ© queue: {queue_stats_final['queue_health']['status']}")
    
    return resume


def traiter_email_individuel_avec_cache_et_rate_limiting(email, tasks_data, rate_limiter, use_optimized_prompts=True):
    """
    Traite un email individuel avec rate limiting.
    Identique Ã  traiter_email_individuel_avec_cache mais enregistre l'appel IA.
    
    Args:
        email: Email Ã  traiter
        tasks_data: DonnÃ©es des tÃ¢ches existantes  
        rate_limiter: Instance du rate limiter
        use_optimized_prompts: Utiliser les prompts IA optimisÃ©s
    """
    # ğŸš€ MÃªme logique que traiter_email_individuel_avec_cache avec optimisations
    resultat = traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts)
    
    # Enregistrer l'appel IA dans le rate limiter
    if resultat["statut"] == "succÃ¨s":
        rate_limiter.register_call()
    
    return resultat

# =====================================
# ğŸ¯ NOUVEAU: TRAITEMENT DES RÃ‰UNIONS
# =====================================

def traiter_reunions(
    use_rate_limiting=False,
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    ğŸ¯ TRAITEMENT UNIFIÃ‰ DES RÃ‰UNIONS
    RÃ©utilise 100% de la logique emails pour les transcriptions de rÃ©unions
    
    Args:
        use_rate_limiting: Activer le rate limiting (mÃªme systÃ¨me que emails)
        use_batch_processing: Traitement par batch (mÃªme systÃ¨me que emails)
        use_cache: Utiliser le cache anti-doublon (mÃªme systÃ¨me que emails)
        use_optimized_prompts: Utiliser les prompts IA optimisÃ©s
    
    Returns:
        dict: RÃ©sultats du traitement des rÃ©unions
    """
    print("ğŸš€ DÃ©marrage traitement intelligent des rÃ©unions...")
    
    try:
        # Import du processeur de rÃ©unions
        from meeting_processor import get_meeting_processor
        
        # Instance du processeur
        processor = get_meeting_processor()
        
        # Traiter toutes les rÃ©unions avec les mÃªmes optimisations que les emails
        optimisations_actives = []
        if use_cache:
            optimisations_actives.append("Cache anti-doublon")
        if use_batch_processing:
            optimisations_actives.append("Batch processing")
        if use_rate_limiting:
            optimisations_actives.append("Rate limiting + Queue")
        if use_optimized_prompts:
            optimisations_actives.append("Prompts optimisÃ©s")
        
        print(f"âš¡ Optimisations actives: {', '.join(optimisations_actives)}")
        
        # Traitement avec cache
        resultat = processor.traiter_toutes_reunions(use_cache=use_cache)
        
        print(f"""
ğŸ“Š RÃ©sumÃ© du traitement intelligent des rÃ©unions:
   ğŸ¯ RÃ©unions total: {resultat['total_meetings']}
   ğŸš€ RÃ©unions traitÃ©es: {resultat['processed']}
   âœ… Nouvelles tÃ¢ches: {resultat['tasks_extracted']}
   ğŸŸ¡ Cache hits: {resultat.get('cache_hits', 0)}
   âŒ Erreurs: {resultat['errors']}
   ğŸ—„ï¸ Optimisations: {len(optimisations_actives)} actives
        """)
        
        return resultat
        
    except Exception as e:
        print(f"âŒ Erreur traitement rÃ©unions: {e}")
        return {
            "total_meetings": 0,
            "processed": 0,
            "tasks_extracted": 0,
            "errors": 1,
            "error": str(e),
            "message": f"Erreur globale: {e}"
        }

import json
import os
from datetime import datetime
import sys

# Ajouter les chemins pour les imports
current_dir = os.path.dirname(__file__)
utils_dir = os.path.join(os.path.dirname(current_dir), "utils")
sys.path.insert(0, utils_dir)
sys.path.insert(0, current_dir)

from agent_task import (
    filtrer_email,
    extract_tasks_from_email,
    suggere_taches_implicites,
    resume_email,
    identifier_departement,
    deduire_priorite,
    # üöÄ NOUVELLES FONCTIONS OPTIMIS√âES
    extract_tasks_optimized,
    suggere_taches_implicites_optimized,
    resume_email_optimized
)
# Import du nouveau syst√®me de cache pour d√©tecter les emails redondants
from cache_emails import (
    calculer_hash_email,
    est_email_deja_traite,
    marquer_email_traite,
    obtenir_info_cache,
    obtenir_statistiques_cache
)
# Import du nouveau syst√®me de batch processing pour performance
from batch_processor import BatchProcessor
# üö¶ NOUVEAU: Import du syst√®me Rate Limiting + Queue  
from rate_limiter import RateLimiter
from email_queue import EmailQueue, detecter_priorite_email_pour_queue

# üîÑ NOUVEAU: Import du gestionnaire unifi√© pour PHASE 2
try:
    from unified_task_manager import get_unified_task_manager
    UNIFIED_SYSTEM_AVAILABLE = True
except ImportError:
    UNIFIED_SYSTEM_AVAILABLE = False
    print("‚ö†Ô∏è Syst√®me unifi√© non disponible, utilisation du syst√®me legacy")

# Configuration des fichiers de donn√©es
# Chemin absolu bas√© sur le r√©pertoire racine du projet
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_FILE = os.path.join(BASE_DIR, "data", "tasks.json")
EMAIL_FILE = os.path.join(BASE_DIR, "data", "emails.json")
LOG_FILE = os.path.join(BASE_DIR, "data", "logs.json")
UNIFIED_TASKS_FILE = os.path.join(BASE_DIR, "data", "unified_tasks.json")

def traiter_emails(
    use_rate_limiting=False,
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    üöÄ FONCTION PRINCIPALE UNIFI√âE: Traitement des emails avec toutes am√©liorations.
    
    Args:
        use_rate_limiting (bool): Active le rate limiting + queue pour protection surcharge
        use_batch_processing (bool): Active le traitement par batch intelligent  
        use_cache (bool): Active le cache anti-doublon pour √©conomies IA
        use_optimized_prompts (bool): Active les prompts IA optimis√©s
                                 
    Int√®gre TOUTES les optimisations pour la production :
    ‚úÖ 1. Cache anti-doublon (√©conomies IA) 
    ‚úÖ 2. Batch processing intelligent
    ‚úÖ 3. Rate limiting + Queue (protection surcharge)
    ‚úÖ 4. Optimisation prompts IA (qualit√© + √©conomies)
    """
    print("üöÄ D√©marrage traitement intelligent des emails...")
    
    # Afficher les optimisations actives
    optimisations = []
    if use_cache:
        optimisations.append("Cache anti-doublon")
    if use_batch_processing:
        optimisations.append("Batch processing")
    if use_rate_limiting:
        optimisations.append("Rate limiting + Queue")
    if use_optimized_prompts:
        optimisations.append("Prompts optimis√©s")
    
    print(f"ÔøΩ Optimisations actives: {', '.join(optimisations)}")
    
    # üö¶ Router vers la bonne m√©thode selon le mode
    if use_rate_limiting:
        print("üö¶ Mode Rate Limiting + Queue activ√©")
        return traiter_emails_avec_rate_limiting(
            use_batch_processing=use_batch_processing,
            use_cache=use_cache,
            use_optimized_prompts=use_optimized_prompts
        )
    else:
        print("‚ö° Mode classique (performances maximales)")
        return traiter_emails_mode_classique(
            use_batch_processing=use_batch_processing,
            use_cache=use_cache,
            use_optimized_prompts=use_optimized_prompts
        )


# üéØ FONCTIONS HELPER POUR OPTIMISATION IA
# ==========================================

def extraire_taches_avec_options(texte_email: str, type_detecte: str, use_optimized_prompts: bool) -> str:
    """
    Helper function qui choisit entre versions optimis√©es ou standard.
    
    Args:
        texte_email: Contenu de l'email
        type_detecte: "explicite" ou "implicite" 
        use_optimized_prompts: Utiliser prompts optimis√©s
        
    Returns:
        str: JSON des t√¢ches extraites
    """
    if type_detecte == "explicite":
        if use_optimized_prompts:
            return extract_tasks_optimized(texte_email, use_optimized_prompts=True)
        else:
            return extract_tasks_from_email(texte_email)
    else:  # implicite
        if use_optimized_prompts:
            return suggere_taches_implicites_optimized(texte_email, use_optimized_prompts=True)
        else:
            return suggere_taches_implicites(texte_email)


def resumer_email_avec_options(texte_email: str, use_optimized_prompts: bool) -> str:
    """
    Helper function pour r√©sumer un email avec ou sans optimisation.
    
    Args:
        texte_email: Contenu de l'email
        use_optimized_prompts: Utiliser prompts optimis√©s
        
    Returns:
        str: R√©sum√© de l'email
    """
    if use_optimized_prompts:
        return resume_email_optimized(texte_email, use_optimized_prompts=True)
    else:
        return resume_email(texte_email)


def traiter_emails_mode_classique(
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    üîß MODE CLASSIQUE: Traitement sans rate limiting (code existant intact).
    Exactement le m√™me comportement qu'avant.
    """
    print("‚ö° Traitement mode classique...")
    
    # Charger emails.json
    with open(EMAIL_FILE, "r", encoding="utf-8") as f:
        emails = json.load(f)

    # Charger tasks.json
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        tasks_data = json.load(f)

    # Initialiser le processeur de batch
    batch_processor = BatchProcessor(batch_size_normal=5, batch_size_urgent=2)
    
    # Compteurs pour statistiques
    taches_totales = 0
    emails_doublons_detectes = 0
    emails_traites_batch = 0
    batches_traites = 0

    # 1. üîç PHASE CACHE: Traiter d'abord les doublons (comme avant)
    emails_apres_cache = []
    
    for email in emails:
        # V√©rifier statut traitement
        if email["statut_traitement"] == "trait√©":
            emails_apres_cache.append(email)
            continue

        # V√©rification cache (logique existante preserv√©e)
        email_hash = calculer_hash_email(email["texte"], email["objet"])
        
        if est_email_deja_traite(email_hash):
            # Email en cache - traitement identique √† l'original
            info_cache = obtenir_info_cache(email_hash)
            
            email["statut_traitement"] = "trait√© (doublon)"
            email["hash_email"] = email_hash
            email["type_email"] = info_cache.get("type_email", "inconnu") if info_cache else "inconnu"
            email["nb_taches_extraites"] = 0

            log_entree = {
                "horodatage": datetime.now().isoformat(timespec='seconds'),
                "email_objet": email["objet"],
                "statut": "doublon d√©tect√©",
                "type_detecte": "cache_hit",
                "hash_email": email_hash,
                "email_original_traite_le": info_cache.get("processed_at") if info_cache else "inconnu",
                "economies_ia": "Appel OpenRouter √©vit√©"
            }
            enregistrer_log(log_entree)
            
            emails_doublons_detectes += 1
            print(f"üü° Doublon d√©tect√© (hash: {email_hash}) ‚Äî Email ignor√© : {email['objet']}")
        
        emails_apres_cache.append(email)

    # 2. üéØ PHASE BATCH: Cr√©er batches intelligents pour emails restants
    batches = batch_processor.creer_batches_intelligents(emails_apres_cache)
    
    if not batches:
        print("‚ÑπÔ∏è Aucun email nouveau √† traiter par batch")
    else:
        stats_batch = batch_processor.obtenir_statistiques_batch(batches)
        print(f"üì¶ {stats_batch['total_batches']} batches cr√©√©s pour {stats_batch['total_emails']} emails")
        print(f"   ‚ö° Urgents: {stats_batch['batches_urgents']} batches")
        print(f"   üìã Normaux: {stats_batch['batches_normaux']} batches")

    # 3. ü§ñ PHASE TRAITEMENT: Traiter chaque batch
    for batch in batches:
        print(f"\nüîÑ Traitement batch {batch['id']} ({batch['type']}) - {batch['taille']} emails")
        
        # Traiter emails du batch individuellement (garde logique existante)
        for email in batch["emails"]:
            try:
                # üöÄ Traitement avec options d'optimisation
                resultat = traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts)
                
                if resultat["statut"] == "succ√®s":
                    taches_totales += resultat["nb_taches"]
                    emails_traites_batch += 1
                    
                    # Marquer dans cache (logique existante)
                    marquer_email_traite(resultat["hash_email"], {
                        "objet": email["objet"],
                        "expediteur": email["expediteur"],
                        "destinataire": email["destinataire"],
                        "nb_taches": resultat["nb_taches"],
                        "type_email": resultat["type_detecte"]
                    })
                    
                    print(f"   ‚úÖ Email trait√©: {resultat['nb_taches']} t√¢ches extraites")
                else:
                    print(f"   ‚ùå Erreur email: {resultat.get('erreur', 'Inconnue')}")
                    
            except Exception as e:
                print(f"   ‚ùå Erreur traitement email: {str(e)}")
                # Log d'erreur
                log_entree = {
                    "horodatage": datetime.now().isoformat(timespec='seconds'),
                    "email_objet": email.get("objet", "unknown"),
                    "statut": "√©chec batch",
                    "erreur": str(e),
                    "batch_id": batch["id"]
                }
                enregistrer_log(log_entree)
        
        batches_traites += 1
        print(f"‚úÖ Batch {batch['id']} termin√©")

    # 4. üíæ SAUVEGARDE: Compatible ancien + nouveau syst√®me
    # LEGACY: Sauvegarder dans l'ancien format (pr√©serv√©)
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(tasks_data, f, indent=4, ensure_ascii=False)

    # üîÑ NOUVEAU: Sauvegarder aussi dans le syst√®me unifi√© si disponible
    if UNIFIED_SYSTEM_AVAILABLE and os.path.exists(UNIFIED_TASKS_FILE):
        try:
            unified_manager = get_unified_task_manager()
            # Ajouter nouvelles t√¢ches au syst√®me unifi√©
            for task in tasks_data:
                # V√©rifier si la t√¢che n'existe pas d√©j√†
                existing_unified_tasks = unified_manager.load_all_tasks()
                task_exists = any(
                    ut.get("source_metadata", {}).get("email_id") == task.get("id")
                    for ut in existing_unified_tasks
                )
                
                if not task_exists:
                    # Convertir vers format unifi√©
                    unified_task_data = {
                        "description": task.get("description", ""),
                        "responsable": task.get("responsable", ""),
                        "deadline": task.get("deadline"),
                        "priorite": task.get("priorite", "medium"),
                        "statut": task.get("statut", "pending"),
                        "confiance_ia": task.get("confiance_ia", 0.8),
                        "source": "email",
                        "type": task.get("type", "explicite"),
                        "source_metadata": {
                            "email_id": task.get("id"),
                            "original_email": task.get("origine_email", {})
                        }
                    }
                    unified_manager.add_task(unified_task_data)
            print("‚úÖ T√¢ches sauvegard√©es dans le syst√®me unifi√©")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde syst√®me unifi√©: {e}")
    
    with open(EMAIL_FILE, "w", encoding="utf-8") as f:
        json.dump(emails_apres_cache, f, indent=4, ensure_ascii=False)

    # 5. üìä STATISTIQUES: Enrichies avec info batch et cache
    stats_cache = obtenir_statistiques_cache()
    
    resume = {
        "emails_traitees": len(emails),  # Compatibilit√© avec l'ancien format
        "emails_traites_batch": emails_traites_batch,
        "taches_ajoutees": taches_totales,
        "doublons_detectes": emails_doublons_detectes,
        "batches_traites": batches_traites,
        "economies_ia": f"{emails_doublons_detectes} appels OpenRouter √©vit√©s par cache",
        "efficacite_batch": f"{batches_traites} batches vs {emails_traites_batch} emails individuels",
        "cache_stats": {
            "total_emails_en_cache": stats_cache.get("total_emails_caches", 0),
            "cache_fonctionnel": stats_cache.get("cache_existe", False)
        }
    }
    
    # Affichage r√©sum√© enrichi
    print(f"\nüìä R√©sum√© du traitement intelligent:")
    print(f"   üìß Emails total: {len(emails)}")
    print(f"   üöÄ Emails trait√©s: {emails_traites_batch}")
    print(f"   ‚úÖ Nouvelles t√¢ches: {taches_totales}")
    print(f"   üü° Doublons √©vit√©s: {emails_doublons_detectes}")
    print(f"   üì¶ Batches utilis√©s: {batches_traites}")
    print(f"   üí∞ √âconomies cache: {emails_doublons_detectes} appels √©vit√©s")
    print(f"   üóÑÔ∏è Cache total: {stats_cache.get('total_emails_caches', 0)} emails")
    
    return resume

def traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts=True):
    """
    Traite un email individuel avec la logique compl√®te du pipeline original.
    Utilis√© par le syst√®me de batch pour garder la compatibilit√©.
    
    Args:
        email: Email √† traiter
        tasks_data: Donn√©es des t√¢ches existantes
        use_optimized_prompts: Utiliser les prompts IA optimis√©s
    """
    
    texte = email["texte"]
    email_hash = calculer_hash_email(email["texte"], email["objet"])

    # Filtrer email (logique originale)
    type_detecte = filtrer_email(texte)

    # üöÄ NOUVEAU: Extraction avec prompts optimis√©s selon param√®tre
    result_text = extraire_taches_avec_options(texte, type_detecte, use_optimized_prompts)

    try:
        taches = json.loads(result_text)
        if not isinstance(taches, list):
            raise ValueError("R√©sultat IA n'est pas une liste")
    except Exception as e:
        # Log d'erreur (logique originale)
        log_entree = {
            "horodatage": datetime.now().isoformat(timespec='seconds'),
            "email_objet": email["objet"],
            "statut": "√©chec",
            "type_detecte": type_detecte,
            "erreur": str(e),
            "resultat_ia": result_text
        }
        enregistrer_log(log_entree)
        
        email["statut_traitement"] = "trait√©"
        email["type_email"] = type_detecte
        email["nb_taches_extraites"] = 0
        email["hash_email"] = email_hash
        
        return {"statut": "√©chec", "erreur": str(e), "nb_taches": 0}

    # üöÄ NOUVEAU: R√©sum√© avec prompts optimis√©s selon param√®tre
    resume = resumer_email_avec_options(texte, use_optimized_prompts)
    if email.get("departement"):
        departement_info = {"nom": email["departement"], "origine": "Utilisateur"}
    else:
        nom_dept = identifier_departement(texte)
        departement_info = {"nom": nom_dept, "origine": "AI"}

    origine_email = {
        "expediteur": email["expediteur"],
        "destinataire": email["destinataire"],
        "objet": email["objet"],
        "date_reception": email["date_reception"],
        "resume_contenu": resume,
        "departement": departement_info
    }

    # Enrichissement t√¢ches (logique originale)
    nouvelles_taches = []
    for tache in taches:
        tache["id"] = f"{email['id']}_{len(nouvelles_taches)+1}"
        if not tache.get("responsable"):
            tache["responsable"] = "inconnu"
        if not tache.get("priorite"):
            tache["priorite"] = deduire_priorite(tache["description"])
        if type_detecte == "explicite":
            tache["confiance_ia"] = 1.0
        elif not tache.get("confiance_ia"):
            tache["confiance_ia"] = 0.7

        tache["source"] = "email"
        tache["type"] = type_detecte
        tache["extrait_le"] = datetime.now().isoformat(timespec='seconds')
        tache["statut"] = "√† faire"
        tache["origine_email"] = origine_email

        tasks_data.append(tache)
        nouvelles_taches.append(tache)

    # Mise √† jour email (logique originale)
    email["statut_traitement"] = "trait√©"
    email["type_email"] = type_detecte
    email["nb_taches_extraites"] = len(nouvelles_taches)
    email["hash_email"] = email_hash

    # Log succ√®s (logique originale avec mention batch)
    log_entree = {
        "horodatage": datetime.now().isoformat(timespec='seconds'),
        "email_objet": email["objet"],
        "statut": "succ√®s",
        "type_detecte": type_detecte,
        "nb_taches": len(nouvelles_taches),
        "hash_email": email_hash,
        "cache_status": "nouveau_email_ajoute_au_cache",
        "traitement_mode": "batch"
    }
    enregistrer_log(log_entree)

    return {
        "statut": "succ√®s",
        "type_detecte": type_detecte,
        "nb_taches": len(nouvelles_taches),
        "hash_email": email_hash
    }

# Fonction utilitaire pour √©crire dans logs.json
def enregistrer_log(entree):
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", encoding="utf-8") as f:
            json.dump([], f, indent=4, ensure_ascii=False)

    with open(LOG_FILE, "r", encoding="utf-8") as f:
        logs = json.load(f)

    logs.append(entree)

    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(logs, f, indent=4, ensure_ascii=False)


def traiter_emails_avec_rate_limiting(
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    üö¶ NOUVEAU MODE: Traitement avec Rate Limiting + Queue.
    Respecte les limites d'appels IA et utilise une file d'attente intelligente.
    """
    print("üö¶ D√©marrage traitement avec rate limiting...")
    
    # Initialiser le rate limiter et la queue
    rate_limiter = RateLimiter(
        calls_per_minute=30,    # Limite conservatrice pour production
        calls_per_hour=800,
        calls_per_day=5000
    )
    email_queue = EmailQueue(max_queue_size=1000)
    
    # Charger emails.json
    with open(EMAIL_FILE, "r", encoding="utf-8") as f:
        emails = json.load(f)

    # Charger tasks.json
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        tasks_data = json.load(f)
    
    # Statistiques
    taches_totales = 0
    emails_doublons_detectes = 0
    emails_traites = 0
    appels_ia_effectues = 0
    temps_attente_total = 0.0
    
    print(f"üìß {len(emails)} emails √† analyser...")
    
    # 1. üîç PHASE CACHE: Traiter les doublons AVANT la queue
    emails_apres_cache = []
    
    for email in emails:
        if email["statut_traitement"] == "trait√©":
            emails_apres_cache.append(email)
            continue

        # V√©rification cache (m√™me logique qu'avant)
        email_hash = calculer_hash_email(email["texte"], email["objet"])
        
        if est_email_deja_traite(email_hash):
            # Email en cache - pas besoin d'IA
            info_cache = obtenir_info_cache(email_hash)
            
            email["statut_traitement"] = "trait√© (doublon)"
            email["hash_email"] = email_hash
            email["type_email"] = info_cache.get("type_email", "inconnu") if info_cache else "inconnu"
            email["nb_taches_extraites"] = 0

            log_entree = {
                "horodatage": datetime.now().isoformat(timespec='seconds'),
                "email_objet": email["objet"],
                "statut": "doublon d√©tect√©",
                "type_detecte": "cache_hit",
                "hash_email": email_hash,
                "mode_traitement": "rate_limited",
                "economies_ia": "Appel OpenRouter √©vit√©"
            }
            enregistrer_log(log_entree)
            
            emails_doublons_detectes += 1
            print(f"üü° Doublon d√©tect√© - √âvite appel IA : {email['objet']}")
        
        emails_apres_cache.append(email)
    
    print(f"‚úÖ Phase cache termin√©e: {emails_doublons_detectes} doublons √©vit√©s")
    
    # 2. üìã PHASE QUEUE: Mettre les emails non-trait√©s en file d'attente
    emails_a_traiter = [e for e in emails_apres_cache if e["statut_traitement"] != "trait√©"]
    
    for email in emails_a_traiter:
        priority = detecter_priorite_email_pour_queue(email)
        email_queue.add_email(email, priority)
    
    queue_stats_initial = email_queue.get_queue_stats()
    print(f"üìã File d'attente cr√©√©e:")
    print(f"   üö® Urgents: {queue_stats_initial['current_queue']['urgent_count']}")
    print(f"   üìã Normaux: {queue_stats_initial['current_queue']['normal_count']}")
    print(f"   üì¶ Batch: {queue_stats_initial['current_queue']['batch_count']}")
    
    # 3. üö¶ PHASE TRAITEMENT: Traiter la queue avec rate limiting
    print(f"\nüö¶ D√©but traitement avec rate limiting...")
    
    while True:
        # R√©cup√©rer le prochain email de la queue
        email = email_queue.get_next_email()
        if not email:
            break
        
        # V√©rifier rate limiting
        if not rate_limiter.can_make_call():
            wait_time = rate_limiter.wait_if_needed()
            temps_attente_total += wait_time
        
        # üöÄ Traiter l'email avec toutes les optimisations
        try:
            resultat = traiter_email_individuel_avec_cache_et_rate_limiting(
                email, tasks_data, rate_limiter, use_optimized_prompts
            )
            
            if resultat["statut"] == "succ√®s":
                taches_totales += resultat["nb_taches"]
                emails_traites += 1
                appels_ia_effectues += 1
                
                # Marquer dans cache
                marquer_email_traite(resultat["hash_email"], {
                    "objet": email["objet"],
                    "expediteur": email["expediteur"],
                    "destinataire": email["destinataire"],
                    "nb_taches": resultat["nb_taches"],
                    "type_email": resultat["type_detecte"]
                })
                
                print(f"   ‚úÖ Email trait√©: {resultat['nb_taches']} t√¢ches | Queue: {email_queue.get_total_queue_size()} restants")
            else:
                print(f"   ‚ùå Erreur: {resultat.get('erreur', 'Inconnue')}")
                
        except Exception as e:
            print(f"   ‚ùå Erreur traitement: {str(e)}")
    
    # 4. üíæ SAUVEGARDE: Identique aux autres modes
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(tasks_data, f, indent=4, ensure_ascii=False)

    with open(EMAIL_FILE, "w", encoding="utf-8") as f:
        json.dump(emails_apres_cache, f, indent=4, ensure_ascii=False)
    
    # 5. üìä STATISTIQUES: Enrichies avec rate limiting
    stats_cache = obtenir_statistiques_cache()
    rate_limiter_stats = rate_limiter.get_current_stats()
    queue_stats_final = email_queue.get_queue_stats()
    
    resume = {
        "emails_traitees": len(emails),
        "emails_traites_rate_limited": emails_traites,
        "taches_ajoutees": taches_totales,
        "doublons_detectes": emails_doublons_detectes,
        "appels_ia_effectues": appels_ia_effectues,
        "temps_attente_total": round(temps_attente_total, 2),
        "economies_ia": f"{emails_doublons_detectes} appels √©vit√©s par cache",
        "rate_limiting_stats": {
            "calls_remaining_minute": rate_limiter_stats["remaining"]["minute"],
            "calls_remaining_hour": rate_limiter_stats["remaining"]["hour"],
            "total_calls_today": rate_limiter_stats["total_calls_today"]
        },
        "queue_stats": {
            "emails_processed": queue_stats_final["overall_stats"]["total_processed"],
            "average_wait_time": round(queue_stats_final["overall_stats"]["average_wait_time"], 2),
            "queue_health": queue_stats_final["queue_health"]["status"]
        },
        "cache_stats": {
            "total_emails_en_cache": stats_cache.get("total_emails_caches", 0),
            "cache_fonctionnel": stats_cache.get("cache_existe", False)
        }
    }
    
    # Affichage r√©sum√© d√©taill√©
    print(f"\nüìä R√©sum√© du traitement avec Rate Limiting:")
    print(f"   üìß Emails total: {len(emails)}")
    print(f"   üöÄ Emails trait√©s: {emails_traites}")
    print(f"   ‚úÖ Nouvelles t√¢ches: {taches_totales}")
    print(f"   üü° Doublons √©vit√©s: {emails_doublons_detectes}")
    print(f"   ü§ñ Appels IA effectu√©s: {appels_ia_effectues}")
    print(f"   ‚è±Ô∏è Temps attente total: {temps_attente_total:.1f}s")
    print(f"   üö¶ Appels restants/heure: {rate_limiter_stats['remaining']['hour']}")
    print(f"   üìã Sant√© queue: {queue_stats_final['queue_health']['status']}")
    
    return resume


def traiter_email_individuel_avec_cache_et_rate_limiting(email, tasks_data, rate_limiter, use_optimized_prompts=True):
    """
    Traite un email individuel avec rate limiting.
    Identique √† traiter_email_individuel_avec_cache mais enregistre l'appel IA.
    
    Args:
        email: Email √† traiter
        tasks_data: Donn√©es des t√¢ches existantes  
        rate_limiter: Instance du rate limiter
        use_optimized_prompts: Utiliser les prompts IA optimis√©s
    """
    # üöÄ M√™me logique que traiter_email_individuel_avec_cache avec optimisations
    resultat = traiter_email_individuel_avec_cache(email, tasks_data, use_optimized_prompts)
    
    # Enregistrer l'appel IA dans le rate limiter
    if resultat["statut"] == "succ√®s":
        rate_limiter.register_call()
    
    return resultat

# =====================================
# üéØ NOUVEAU: TRAITEMENT DES R√âUNIONS
# =====================================

def traiter_reunions(
    use_rate_limiting=False,
    use_batch_processing=True,
    use_cache=True,
    use_optimized_prompts=True
    ):
    """
    üéØ TRAITEMENT UNIFI√â DES R√âUNIONS
    R√©utilise 100% de la logique emails pour les transcriptions de r√©unions
    
    Args:
        use_rate_limiting: Activer le rate limiting (m√™me syst√®me que emails)
        use_batch_processing: Traitement par batch (m√™me syst√®me que emails)
        use_cache: Utiliser le cache anti-doublon (m√™me syst√®me que emails)
        use_optimized_prompts: Utiliser les prompts IA optimis√©s
    
    Returns:
        dict: R√©sultats du traitement des r√©unions
    """
    print("üöÄ D√©marrage traitement intelligent des r√©unions...")
    
    try:
        # Import du processeur de r√©unions
        from meeting_processor import get_meeting_processor
        
        # Instance du processeur
        processor = get_meeting_processor()
        
        # Traiter toutes les r√©unions avec les m√™mes optimisations que les emails
        optimisations_actives = []
        if use_cache:
            optimisations_actives.append("Cache anti-doublon")
        if use_batch_processing:
            optimisations_actives.append("Batch processing")
        if use_rate_limiting:
            optimisations_actives.append("Rate limiting + Queue")
        if use_optimized_prompts:
            optimisations_actives.append("Prompts optimis√©s")
        
        print(f"‚ö° Optimisations actives: {', '.join(optimisations_actives)}")
        
        # Traitement avec cache
        resultat = processor.traiter_toutes_reunions(use_cache=use_cache)
        
        print(f"""
üìä R√©sum√© du traitement intelligent des r√©unions:
   üéØ R√©unions total: {resultat['total_meetings']}
   üöÄ R√©unions trait√©es: {resultat['processed']}
   ‚úÖ Nouvelles t√¢ches: {resultat['tasks_extracted']}
   üü° Cache hits: {resultat.get('cache_hits', 0)}
   ‚ùå Erreurs: {resultat['errors']}
   üóÑÔ∏è Optimisations: {len(optimisations_actives)} actives
        """)
        
        return resultat
        
    except Exception as e:
        print(f"‚ùå Erreur traitement r√©unions: {e}")
        return {
            "total_meetings": 0,
            "processed": 0,
            "tasks_extracted": 0,
            "errors": 1,
            "error": str(e),
            "message": f"Erreur globale: {e}"
        }

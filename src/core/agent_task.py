# -*- coding: utf-8 -*-
import os
import openai
from dotenv import load_dotenv
from datetime import datetime
import json

# Charger la cl√© API depuis .env
load_dotenv()
api_key = os.getenv("OPENROUTER_API_KEY")

# Configurer le client OpenRouter
client = openai.OpenAI(
    api_key=api_key,
    base_url="https://openrouter.ai/api/v1"
)

# ‚úÖ Fonction 1 : Extraire les t√¢ches d‚Äôun email explicite
def extract_tasks_from_email(text_email: str):
    prompt = f"""
        Lis cet email et extrais toutes les t√¢ches clairement mentionn√©es.

        Donne chaque t√¢che sous forme de liste JSON, avec les champs suivants :
            - "description"
            - "responsable"
            - "deadline"
            - "priorite"

        Retourne uniquement le JSON, sans aucun texte autour.

        Email :
    {text_email}
        """
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

# ‚úÖ Fonction 2 : R√©sumer le contenu de l‚Äôemail (2 lignes max)
def resume_email(text_email: str):
    prompt = f"""
        Lis cet email et donne un court r√©sum√© de 1 ou 2 phrases maximum.
        Rends uniquement le texte r√©sum√©, sans autre commentaire.

        Email :
    {text_email}
        """
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()

# ‚úÖ Fonction 3 : Identifier le d√©partement concern√© par l‚Äôemail
def identifier_departement(text_email: str):
    prompt = f"""
        Lis cet email et d√©duis le d√©partement concern√© (ex: RH, Finance, IT, Marketing).
        Retourne uniquement le nom du d√©partement, sans phrase autour.

        Email :
    {text_email}
        """
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()


# ‚úÖ Fonction 4 : D√©duire la priorit√© d'une t√¢che (bas√©e sur sa description)
def deduire_priorite(description: str):
    prompt = f"""
        Lis la description suivante d'une t√¢che et donne sa priorit√© : √©lev√©e, moyenne ou faible.
        Retourne uniquement le mot : √©lev√©e, moyenne ou faible.

        Description :
    {description}
        """
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip().lower()


# ‚úÖ Fonction 4 : Sugg√©rer des t√¢ches implicites √† partir d‚Äôun email
def suggere_taches_implicites(text_email: str):
    prompt = f"""
        Lis attentivement cet email.
        M√™me s‚Äôil ne contient pas d‚Äôordres clairs, d√©duis toutes les t√¢ches possibles que l‚Äô√©quipe devrait faire, en fonction du contexte.
        Pour chaque t√¢che, donne les √©l√©ments suivants :
            - "description" : ce qu‚Äôil faut faire (phrase courte)
            - "responsable" : si identifiable dans l‚Äôemail (sinon √©cris "inconnu")
            - "priorite" : √©lev√©e / moyenne / faible (estimation logique)
            - "confiance_ia" : un nombre entre 0.5 et 1.0 selon la fiabilit√© de la t√¢che (1.0 = tr√®s s√ªr, 0.5 = incertain)

        Retourne uniquement la liste JSON des t√¢ches, sans texte autour.
        Email :
    {text_email}
        """

    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()

# Fonction IA : Filtrer un email pour d√©terminer son type
def filtrer_email(text_email: str):
    prompt = f"""
        Lis cet email et d√©termine s‚Äôil contient des instructions ou demandes claires d‚Äôaction.
        Si oui, r√©ponds uniquement : "explicite".
        Si non, r√©ponds uniquement : "implicite".

        D√©finition :
            - explicite : ordres clairs, actions demand√©es
            - implicite : contexte, attentes, pas de t√¢che exprim√©e

        Ne donne aucune explication. Retourne seulement "explicite" ou "implicite".

        Email :
    {text_email}
        """

    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    result = response.choices[0].message.content.strip().lower()
    return result  # "explicite" ou "implicite"


# üöÄ AM√âLIORATION #4: OPTIMISATION DES PROMPTS IA
# ================================================

def optimiser_prompt_pour_extraction(texte_email: str, type_extraction: str) -> str:
    """
    üéØ OPTIMISATION PROMPTS IA: G√©n√®re des prompts optimis√©s selon le contexte.
    
    Am√©liore la qualit√© des r√©ponses IA et r√©duit la consommation de tokens :
    - Prompts plus courts et pr√©cis
    - Instructions claires et structur√©es  
    - Adapt√©s au type d'email (explicite/implicite)
    - Format de sortie standardis√©
    
    Args:
        texte_email: Le contenu de l'email √† analyser
        type_extraction: "explicite" ou "implicite"
        
    Returns:
        str: Prompt optimis√© pour l'IA
    """
    
    # Analyser la longueur et complexit√© de l'email
    longueur_email = len(texte_email)
    mots_cles_urgents = ["urgent", "asap", "critique", "imm√©diat", "emergency"]
    est_urgent = any(mot in texte_email.lower() for mot in mots_cles_urgents)
    
    # Base commune optimis√©e (tokens r√©duits)
    base_prompt = "Analyse cet email et extrait les t√¢ches en JSON strict.\n\n"
    
    if type_extraction == "explicite":
        # Prompt optimis√© pour t√¢ches explicites
        prompt_specifique = """Trouve UNIQUEMENT les t√¢ches clairement demand√©es.

    Format JSON requis:
    [{"description":"...","responsable":"...","deadline":"...","priorite":"..."}]

    R√®gles:
        - Description: action pr√©cise demand√©e
        - Responsable: qui doit faire (nom/service)  
        - Deadline: quand (date ou "inconnue")
        - Priorit√©: "haute/normale/basse" """

        if est_urgent:
            prompt_specifique += "\n- Email URGENT: priorit√© haute par d√©faut"
            
    else:  # implicite
        # Prompt optimis√© pour t√¢ches implicites
        prompt_specifique = """Identifie les t√¢ches SOUS-ENTENDUES (non explicites).

    Format JSON requis:
    [{"description":"...","responsable":"...","priorite":"...","confiance_ia":0.0-1.0}]

    R√®gles:
        - Description: action implicite n√©cessaire
        - Responsable: qui pourrait s'en charger
        - Priorit√©: importance estim√©e
        - Confiance_ia: certitude de 0.0 √† 1.0"""

    # Limiter la longueur selon l'email
    if longueur_email > 1000:
        prompt_specifique += "\n\nEmail long: concentre-toi sur l'essentiel."
    
    # Prompt final optimis√©
    prompt_final = base_prompt + prompt_specifique + f"\n\nEmail:\n{texte_email}\n\nJSON:"
    
    return prompt_final


def extract_tasks_optimized(texte_email: str, use_optimized_prompts: bool = True) -> str:
    """
    üéØ EXTRACTION T√ÇCHES AVEC PROMPTS OPTIMIS√âS.
    Version am√©lior√©e de extract_tasks_from_email.
    
    Args:
        texte_email: Contenu de l'email
        use_optimized_prompts: Utiliser les prompts optimis√©s (True) ou standard (False)
        
    Returns:
        str: JSON des t√¢ches extraites
    """
    
    if use_optimized_prompts:
        # Nouveau prompt optimis√©
        prompt = optimiser_prompt_pour_extraction(texte_email, "explicite")
    else:
        # Ancien prompt standard (fallback)
        prompt = f"""
        Lis cet email et extrais toutes les t√¢ches clairement mentionn√©es.

        Donne chaque t√¢che sous forme de liste JSON, avec les champs suivants :
            - "description"
            - "responsable"
            - "deadline"
            - "priorite"

        Retourne uniquement le JSON, sans aucun texte autour.

        Email : {texte_email}
        """
    
    try:
        response = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,  # Optimis√© pour r√©duire les co√ªts
            temperature=0.1  # Plus d√©terministe
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur extraction optimis√©e: {e}")
        # Fallback vers m√©thode standard
        return extract_tasks_from_email(texte_email)


def suggere_taches_implicites_optimized(texte_email: str, use_optimized_prompts: bool = True) -> str:
    """
    üí° SUGGESTIONS T√ÇCHES IMPLICITES AVEC PROMPTS OPTIMIS√âS.
    Version am√©lior√©e de suggere_taches_implicites.
    
    Args:
        texte_email: Contenu de l'email
        use_optimized_prompts: Utiliser les prompts optimis√©s
        
    Returns:
        str: JSON des t√¢ches implicites sugg√©r√©es
    """
    
    if use_optimized_prompts:
        # Nouveau prompt optimis√©
        prompt = optimiser_prompt_pour_extraction(texte_email, "implicite")
    else:
        # Ancien prompt standard (fallback)
        prompt = f"""
        Analyse cet email et sugg√®re des t√¢ches implicites qui pourraient √™tre n√©cessaires.

        Pour chaque t√¢che implicite, donne :
            - "description"
            - "responsable" 
            - "priorite"
            - "confiance_ia" (entre 0.0 et 1.0)

        Retourne uniquement le JSON, sans texte autour.

        Email : {texte_email}
        """
    
    try:
        response = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=600,  # Optimis√© pour r√©duire les co√ªts
            temperature=0.2  # L√©g√®rement plus cr√©atif pour suggestions
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur suggestions optimis√©es: {e}")
        # Fallback vers m√©thode standard
        return suggere_taches_implicites(texte_email)


def resume_email_optimized(texte_email: str, use_optimized_prompts: bool = True) -> str:
    """
    üìù R√âSUM√â EMAIL AVEC PROMPTS OPTIMIS√âS.
    Version am√©lior√©e de resume_email.
    
    Args:
        texte_email: Contenu de l'email
        use_optimized_prompts: Utiliser les prompts optimis√©s
        
    Returns:
        str: R√©sum√© optimis√© de l'email
    """
    
    if use_optimized_prompts:
        # Prompt optimis√© court et efficace
        longueur = len(texte_email)
        if longueur < 200:
            prompt = f"R√©sume en 1 phrase:\n{texte_email}"
        elif longueur < 500:
            prompt = f"R√©sume en 2-3 phrases cl√©s:\n{texte_email}"
        else:
            prompt = f"R√©sume les points essentiels en 3-4 phrases:\n{texte_email}"
    else:
        # Ancien prompt standard
        prompt = f"R√©sume ce email en quelques phrases : {texte_email}"
    
    try:
        response = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=150,  # R√©sum√© concis
            temperature=0.0  # D√©terministe
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur r√©sum√© optimis√©: {e}")
        # Fallback vers m√©thode standard
        return resume_email(texte_email)

